---
title: "How does emotions can be reflected within Lyrics!"
author: "Tong Dai"
date: "9/6/2019"
output: html_document
---


![ ](../figs/music.png)


This report will demonstrate how lyrics especially the words choosing used within Lyrics can reflect humans emotion and behaviors


About datasets: 

"lyrics.csv" is a filtered corpus of 380,000+ song lyrics from from MetroLyrics. You can read more about it on [Kaggle](https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics). 

"artists.csv" provides the background information of all the artistis. These information are scraped from [LyricsFreak](https://www.lyricsfreak.com/).
  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#### Package descriptions:

+ `tm` is a framework for text mining applications within R;
+ `tidytext` allows text mining using 'dplyr', 'ggplot2', and other tidy tools;
+ `tidyverse` is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures;
+ `DT` provides an R interface to the JavaScript library DataTables;
+ `wordcloud` provides visual presentation of text distribution;
+ `scales` graphical scales map data to aesthetics, and provide methods for automatically determining breaks and labels for axes and legends.
+ `gridExtra` Provides a number of user-level functions to work with "grid" graphics, notably to arrange multiple grid-based plots on a page, and draw tables;
+ `ngram` An n-gram is a sequence of n "words" taken, in order, from a body of text;
+ `igraph` Routines for simple graphs and network analysis;
+ `ggraph` The grammar of graphics as implemented in ggplot2 is a poor fit for graph and network visualizations due to its reliance on tabular data input;
+ `rsconnect` Programmatic deployment interface for 'RPubs', 'shinyapps.io', and 'RStudio Connect'. Supported content types include R Markdown documents, Shiny applications, Plumber APIs, plots, and static web content;
+ `data.table` is a package for fast aggregation of large data.


#### Load required packages

```{r, message=FALSE, warning=FALSE,echo=FALSE}
packages.used=c("tm", "tidytext","tidyverse","DT","wordcloud","scales","gridExtra","ngram","igraph","ggraph","rsconnect")

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(wordcloud)
library(scales)
library(gridExtra)
library(ngram)
library(igraph)
library(ggraph)
library(rsconnect)
library(dplyr)

# Ref: https://github.com/TZstatsADS/Fall2018-Proj1-wanghouyaoleyao/blob/master/doc/Proj1-HappyMoments.Rmd
```


This report is prepared with the following environmental settings.

```{r}
print(R.version)
```


#### Read Data

```{r}
# load lyrics data
load(file = "../data/lyrics.RData")

# dt_lyrics %>% count(year)
# narrow down subset of dataset
lyrics_df<-subset(dt_lyrics, year == 2006 | year == 2016)
```


After file (lyrics.RData) is loaded, I performed below steps to clean the dataset and turn it into readable format, specifically by removing stopwords and creating a tidy version of texts which is saved in $ output $ file.

Then,I combine the processed data with Artist information ‘artists.csv’ saved in $ data $ file to generate the dataset for this report.


#### Cleaning of text

We clean the text by converting all the letters to the lower case, and removing punctuation, numbers, empty words and extra white space.


```{r text processing in tm,warning=FALSE, message=FALSE,echo=FALSE}

# function for removimg leading and trailing whitespace from character strings 
leadingWhitespace <- content_transformer(function(x) str_trim(x, side = "both"))

# clean the data and make a corpus
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
  tm_map(content_transformer(tolower))%>%
  tm_map(removePunctuation)%>%
  tm_map(removeNumbers)%>%
  tm_map(removeWords, character(0))%>%
  tm_map(stripWhitespace)%>%
  tm_map(leadingWhitespace)
```


#### Stemming words and converting tm object to tidy object

Stemming reduces a word to its word *stem*. We stem the words here and then convert the "tm" object to a "tidy" object for much faster processing.

```{r stemming}
stemmed <- tm_map(corpus, stemDocument) %>%
  tidy() %>%
  select(text)
```


#### Creating tidy format of the dictionary to be used for completing stems

We also need a dictionary to look up the words corresponding to the stems.

```{r tidy dictionary}
dict <- tidy(corpus) %>%
  select(text) %>%
  unnest_tokens(dictionary, text)
```


#### remove stop words
```{r stopwords,warning=FALSE, message=FALSE,echo=FALSE}
data("stop_words")
word <- c("lot", "today", "months", "month", "wanna", "wouldnt", "wasnt", "ha", "na", "ooh", "da",
        "gonna", "im", "dont", "aint", "wont", "yeah", "la", "oi", "nigga", "fuck",
          "hey", "year", "years", "last", "past", "feel")
stop_words <- stop_words %>%
  bind_rows(mutate(tibble(word), lexicon = "updated"))
```



#### Combining stems and dictionary into the same tibble

Here we combine the stems and the dictionary into the same "tidy" object.

```{r tidy stems with dictionary}
completed <- stemmed %>%
  mutate(id = row_number()) %>%
  unnest_tokens(stems, text) %>%
  bind_cols(dict) 
```


### Stem completion

Lastly, we complete the stems by picking the corresponding word with the highest frequency.

```{r stem completion, warning=FALSE, message=FALSE}
completed <- completed %>%
  group_by(stems) %>%
  count(dictionary) %>%
  mutate(word = dictionary[which.max(n)]) %>%
  ungroup() %>%
  select(stems, word) %>%
  distinct() %>%
  right_join(completed) %>%
  select(-stems)
```

### Pasting stem completed individual words into their respective lyrics

We want our processed words to resemble the structure of the original lyrics. So we paste the words together to form processed lyrics.

```{r reverse unnest}
completed <- completed %>%
  group_by(id) %>%
  summarise(stemmedwords= str_c(word, collapse = " ")) %>%
  ungroup()
```

### Keeping a track of the processed lyrics with their own ID

```{r cleaned hm_data, warning=FALSE, message=FALSE}
dt_lyrics <- dt_lyrics %>%
  mutate(id = row_number()) %>%
  inner_join(completed)
```

### Exporting the processed text data into a CSV file

```{r export data}
save(dt_lyrics, file="../output/processed_lyrics.RData")
```










